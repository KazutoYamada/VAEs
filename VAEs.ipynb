{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPredJ7CDIrLVw8AnLCV6gi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KazutoYamada/VAEs/blob/main/VAEs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VAEs**\n",
        "\n",
        "以下の基本的なVAEの学習用ノートブック（PyTorch）です。\n",
        "\n",
        "\n",
        "1.   VAE（Variational Autoencoder）\n",
        "2.   Convolutional VAE\n",
        "3.   Conditional VAE\n",
        "\n",
        "学習データは、MNIST(28,28,1)、CIFAR10(32,32,3)、ラベル付きオリジナルデータ(resize_to_32,32,3)を利用可能です。 オリジナルデータを使用の際、ファイル名かデータ名のどちらにラベルされているかで仕様が異なります。\n"
      ],
      "metadata": {
        "id": "-fvF6GXaK-6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0. 学習データの準備**\n",
        "\n",
        "※Convolutional VAEの際はtransformの一次元化をコメントアウトにする必要あり。\n",
        "\n",
        "※画像サイズに合わせてモデルのパラメータ変更必要。"
      ],
      "metadata": {
        "id": "6dyq3508LPr0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzTjVRvWHhHB"
      },
      "outputs": [],
      "source": [
        "#コラボのマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ライブラリのインポート\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import skimage\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "GhIP1RDxLSFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.1. MNISTなどダウンロードデータを使用の際"
      ],
      "metadata": {
        "id": "lKmWX__hLWCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Lambda(lambda x: x.view(-1))])\n",
        "\n",
        "#MNIST_data\n",
        "train_data =  datasets.MNIST('./data/MNIST', train=True, download=True, transform = transform)\n",
        "val_data =  datasets.MNIST('./data/MNIST', train=False, download=True, transform = transform)\n",
        "\n",
        "#CIFAR10\n",
        "\n",
        "\"\"\"train_data = datasets.CIFAR10('/data/CIFAR10', train=True, download=True, transform = transform)\n",
        "val_data = datasets.CIFAR10('/data/CIFAR10', train=False, download=True, transform = transform)\"\"\"\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "SFGZOkNILVCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.2.オリジナルデータを使用の際（データ名ごとにラベル付けしている場合）"
      ],
      "metadata": {
        "id": "r19fmTG6MVVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir_name = \"/content/drive/My Drive/\"\n",
        "image_name_list = os.listdir(dir_name)\n",
        "\n",
        "#データ前処理\n",
        "\n",
        "class dataset(Dataset):\n",
        "    def __init__(self, image_name_list):\n",
        "        self.image_name_list = image_name_list\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Lambda(lambda x: x.view(-1))])\n",
        "    def __len__(self):\n",
        "        return len(self.image_name_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_name = self.image_name_list[idx]\n",
        "        image = skimage.io.imread(dir_name + image_name)\n",
        "        image = skimage.transform.resize(image, (32,32))\n",
        "        trans_image = self.transform(image[:,:,:3])\n",
        "        label = int(image_name.split(\".\")[0])\n",
        "        return trans_image, torch.Tensor([label])\n",
        "\n",
        "#データ読み込み\n",
        "train_val_dataset = dataset(image_name_list)\n",
        "\n",
        "train_rate = 0.7\n",
        "\n",
        "train_size = int(train_rate * len(train_val_dataset))\n",
        "val_size = len(train_val_dataset) - train_size\n",
        "\n",
        "train_data, val_data = random_split(train_val_dataset,[train_size, val_size]])\n",
        "\n",
        "train_loader = DataLoader(dataset, batch_size = 32, shuffle= True, drop_last = False)\n",
        "val_loader = DataLoader(dataset, batch_size = 32, shuffle= False, drop_last = False)"
      ],
      "metadata": {
        "id": "_cCze9d-MUbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.3.オリジナルデータを使用の際（ファイル名ごとにラベル付けしている場合）"
      ],
      "metadata": {
        "id": "wyQx2gNONJTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir_name = \"/content/drive/My Drive/\"\n",
        "image_name_list = os.listdir(dir_name)\n",
        "\n",
        "#データ前処理\n",
        "data_transform = transforms.Compose([transforms.Resize((32,32)),\n",
        "                                    transforms.ToTensor(),\n",
        "                                     transforms.Lambda(lambda x: x.view(-1))])\n",
        "\n",
        "#データ読み込み\n",
        "train_val_dataset = datasets.ImageFolder(dir_name, data_transform)\n",
        "\n",
        "#あとは0.2と同じ"
      ],
      "metadata": {
        "id": "jgh2D4smNRSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. VAE"
      ],
      "metadata": {
        "id": "msOLPWkXOGF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ハイパーパラメータの設定\n",
        "epochs = 5\n",
        "lr = 0.001\n",
        "beta = 1\n",
        "z_dim = 200\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch.manual_seed(0)\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "T7m6UQB6OKxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#モデル設定\n",
        "\n",
        "def torch_log(x):\n",
        "    return torch.log(torch.clamp(x, min=1e-10))\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, z_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        #Encoder\n",
        "        self.ln_en = nn.Linear(32*32*3,1000)\n",
        "        self.ln_en_mean = nn.Linear(1000,z_dim)\n",
        "        self.ln_en_std = nn.Linear(1000,z_dim)\n",
        "\n",
        "        #Decoder\n",
        "        self.ln_de1 = nn.Linear(z_dim,1000)\n",
        "        self.ln_de2 = nn.Linear(1000, 32*32*3)\n",
        "\n",
        "    def encoder(self, x):\n",
        "        x = F.relu(self.ln_en(x))\n",
        "        mean = self.ln_en_mean(x)\n",
        "        std = F.softplus(self.ln_en_std(x))\n",
        "        return mean, std\n",
        "\n",
        "    def re_trick(self, mean, std):\n",
        "        if self.training:\n",
        "            epsilon = torch.randn(mean.shape).to(device)\n",
        "            return mean + std * epsilon\n",
        "        else:\n",
        "            return mean\n",
        "\n",
        "    def decoder(self, z):\n",
        "        x = F.relu(self.ln_de1(z))\n",
        "        x = torch.sigmoid(self.ln_de2(x))\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean, std = self.encoder(x)\n",
        "        z = self.re_trick(mean, std)\n",
        "        x = self.decoder(z)\n",
        "        return x, z\n",
        "\n",
        "    def loss(self, x):\n",
        "        mean, std = self.encoder(x)\n",
        "        KL = -0.5 * torch.mean(torch.sum(1+torch_log(std**2) - mean**2 - std**2, dim = 1))\n",
        "\n",
        "        z = self.re_trick(mean, std)\n",
        "        y = self.decoder(z)\n",
        "        #recon = -torch.mean(torch.sum(x*torch_log(y)+(1-x)*torch_log(1-y), dim=1)) #ベルヌーイ分布のとき\n",
        "        recon = torch.mean(torch.sum((y-x)**2, dim=1))\n",
        "        return KL, recon"
      ],
      "metadata": {
        "id": "tuTVGeBeOPTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#学習\n",
        "model  = VAE(z_dim).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "epoch_train_losses = []\n",
        "epoch_val_losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    batch_train_loss = []\n",
        "    batch_val_loss = []\n",
        "\n",
        "    model.train()\n",
        "    for x, _ in train_loader: #train_loader\n",
        "        x = x.to(device)\n",
        "        model.zero_grad()\n",
        "        KL, recon = model.loss(x)\n",
        "        loss = beta * KL + recon\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        batch_train_loss.append(loss.cpu().detach().numpy())\n",
        "    epoch_train_losses.append(np.average(batch_train_loss))\n",
        "\n",
        "    model.eval()\n",
        "    for x, _ in val_loader: #val_loader\n",
        "        x = x.to(device)\n",
        "        KL, recon = model.loss(x)\n",
        "        loss = beta * KL + recon\n",
        "        batch_val_loss.append(loss.cpu().detach().numpy())\n",
        "    epoch_val_losses.append(np.average(batch_val_loss))\n",
        "\n",
        "    print(\"{} EPOCH: Train_Loss -> {}, Val_Loss -> {}\".format(epoch, np.average(batch_train_loss), np.average(batch_val_loss)))\n",
        "\n",
        "plt.plot(range(len(epoch_train_losses)), epoch_train_losses, label=\"Train_Loss\")\n",
        "plt.plot(range(len(epoch_val_losses)), epoch_val_losses, label=\"Val_Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "j8sYSRF6Oetg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#画像確認\n",
        "\n",
        "#元画像\n",
        "fig = plt.figure(figsize=(3,3))\n",
        "for i in range(9):\n",
        "    x, _ = val_data[i] #val_data\n",
        "    im = x.view(-1,28, 28).permute(1,2,0).squeeze().numpy()\n",
        "\n",
        "    ax = fig.add_subplot(3,3,i+1)\n",
        "    ax.imshow(im)\n",
        "\n",
        "#再構成画像\n",
        "\n",
        "model.eval()\n",
        "\n",
        "fig = plt.figure(figsize=(3,3))\n",
        "for i in range(9):\n",
        "    x, _ = val_data[i] #val_data\n",
        "    x = x.unsqueeze(0).to(device)\n",
        "    y, z = model(x)\n",
        "    im = y.view(-1, 28, 28).permute(1,2,0).detach().cpu().squeeze().numpy()\n",
        "\n",
        "    ax = fig.add_subplot(3,3,i+1)\n",
        "    ax.imshow(im)"
      ],
      "metadata": {
        "id": "ztwg3mv-Pxk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#潜在空間の確認\n",
        "\n",
        "model.eval()\n",
        "\n",
        "z_list = []\n",
        "t_list = []\n",
        "\n",
        "for x, t in val_data:\n",
        "    t_list.append(t)\n",
        "    x = x.to(device).unsqueeze(0)\n",
        "    _, z = model(x)\n",
        "    z_list.append(z.cpu().detach().numpy()[0])\n",
        "\n",
        "z_val = np.stack(z_list)\n",
        "\n",
        "#線形なPCAでの次元削減\n",
        "\n",
        "z_reduc = PCA(n_components = 2).fit_transform(z_val).T\n",
        "\n",
        "colors = ['khaki', 'lightgreen', 'cornflowerblue', 'violet', 'sienna', 'darkturquoise', 'slateblue', 'orange', 'darkcyan', 'tomato']\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.scatter(*z_reduc, s = 0.7, c =[colors[t] for t in t_list])\n",
        "\n",
        "for i in range(10):\n",
        "    plt.scatter([],[], c = colors[i], label=i)\n",
        "plt.legend()\n",
        "\n",
        "#非線形なtSNEでの次元削減\n",
        "z_reduc = TSNE(n_components = 2).fit_transform(z_val).T\n",
        "\n",
        "colors = ['khaki', 'lightgreen', 'cornflowerblue', 'violet', 'sienna', 'darkturquoise', 'slateblue', 'orange', 'darkcyan', 'tomato']\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.scatter(*z_reduc, s = 0.7, c =[colors[t] for t in t_list])\n",
        "\n",
        "for i in range(10):\n",
        "    plt.scatter([],[], c = colors[i], label=i)\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "4tF45uTRP0fY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Convolutional VAE**"
      ],
      "metadata": {
        "id": "kAG3iwTOQgqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#モデル設定\n",
        "\n",
        "def torch_log(x):\n",
        "    return torch.log(torch.clamp(x, min=1e-10))\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, z_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        #Encoder\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(3,64,3,padding = 1), #(32,32,3)の画像を想定\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64,64,3,padding = 1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(64,128,3,padding = 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128,128,3,padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv2d1 = nn.Conv2d(128,128, 3)\n",
        "\n",
        "        self.maxpooling = nn.MaxPool2d(2)\n",
        "\n",
        "        self.ln_en = nn.Linear(6*6*128,1000)\n",
        "        self.ln_en_mean = nn.Linear(1000,z_dim)\n",
        "        self.ln_en_std = nn.Linear(1000,z_dim)\n",
        "\n",
        "        #Decoder\n",
        "        self.ln_de1 = nn.Linear(z_dim,1000)\n",
        "        self.ln_de2 = nn.Linear(1000, 9*9*128)\n",
        "\n",
        "        self.conv2d2 = nn.Conv2d(128,128, 3, padding = 1)\n",
        "\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(128,128,3,padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128,64,3,padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(64,64,3),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64,3,3),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode=\"bilinear\")\n",
        "\n",
        "    def encoder(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.maxpooling(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.maxpooling(x)\n",
        "        x = self.conv2d1(x)\n",
        "        x = x.view(-1,6*6*128)\n",
        "        x = self.ln_en(x)\n",
        "        mean = self.ln_en_mean(x)\n",
        "        std = F.softplus(self.ln_en_std(x))\n",
        "        return mean, std\n",
        "\n",
        "    def re_trick(self, mean, std):\n",
        "        if self.training:\n",
        "            epsilon = torch.randn(mean.shape).to(device)\n",
        "            return mean + std * epsilon\n",
        "        else:\n",
        "            return mean\n",
        "\n",
        "    def decoder(self, z):\n",
        "        x = F.relu(self.ln_de1(z))\n",
        "        x = F.relu(self.ln_de2(x))\n",
        "        x = x.view(-1,128,9,9)\n",
        "        x = self.conv2d2(x)\n",
        "        x = self.upsample(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.upsample(x)\n",
        "        x = self.convblock4(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean, std = self.encoder(x)\n",
        "        z = self.re_trick(mean, std)\n",
        "        x = self.decoder(z)\n",
        "        return x, z\n",
        "\n",
        "    def loss(self, x):\n",
        "        mean, std = self.encoder(x)\n",
        "        KL = -0.5 * torch.sum(1+torch_log(std**2) - mean**2 - std**2)/ batch_size\n",
        "\n",
        "        z = self.re_trick(mean, std)\n",
        "        y = self.decoder(z)\n",
        "        #recon = -torch.mean(torch.sum(x*torch_log(y)+(1-x)*torch_log(1-y), dim=1))\n",
        "        recon = torch.sum((y-x)**2) / batch_size\n",
        "        return KL, recon"
      ],
      "metadata": {
        "id": "DLNLMS7JQmZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#学習\n",
        "model  = VAE(z_dim).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "epoch_train_losses = []\n",
        "epoch_val_losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    batch_train_loss = []\n",
        "    batch_val_loss = []\n",
        "\n",
        "\n",
        "    model.train()\n",
        "    for x, _ in dataloader: #train_loader\n",
        "        x = x.to(device)\n",
        "        model.zero_grad()\n",
        "        KL, recon = model.loss(x)\n",
        "        loss = beta * KL + recon\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        batch_train_loss.append(loss.cpu().detach().numpy())\n",
        "    epoch_train_losses.append(np.average(batch_train_loss))\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    for x, _ in dataloader: #val_loader\n",
        "        x = x.to(device)\n",
        "        KL, recon = model.loss(x)\n",
        "        loss = beta * KL + recon\n",
        "        batch_val_loss.append(loss.cpu().detach().numpy())\n",
        "    epoch_val_losses.append(np.average(batch_val_loss))\n",
        "\n",
        "    print(\"{} EPOCH: Train_Loss -> {}, Val_Loss -> {}\".format(epoch, np.average(batch_train_loss), np.average(batch_val_loss)))\n",
        "\n",
        "plt.plot(range(len(epoch_train_losses)), epoch_train_losses, label=\"Train_Loss\")\n",
        "plt.plot(range(len(epoch_val_losses)), epoch_val_losses, label=\"Val_Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VXzjCcSNRCT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#画像確認\n",
        "\n",
        "fig = plt.figure(figsize=(3,3))\n",
        "for i in range(9):\n",
        "    x, _ = dataset[i] #train_data\n",
        "    im = x.view(-1, 32, 32).permute(1,2,0).squeeze().numpy()\n",
        "\n",
        "    ax = fig.add_subplot(3,3,i+1)\n",
        "    ax.imshow(im)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "fig = plt.figure(figsize=(3,3))\n",
        "for i in range(9):\n",
        "    x, _ = dataset[i] #val_data\n",
        "    x = x.unsqueeze(0).to(device)\n",
        "    y, z = model(x)\n",
        "    im = y.view(-1, 32, 32).permute(1,2,0).detach().cpu().squeeze().numpy()\n",
        "\n",
        "    ax = fig.add_subplot(3,3,i+1)\n",
        "    ax.imshow(im)"
      ],
      "metadata": {
        "id": "X8VcwQPNRLZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.Conditional VAE**"
      ],
      "metadata": {
        "id": "9DuaQo7TRfe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#モデル設定\n",
        "\n",
        "def torch_log(x):\n",
        "    return torch.log(torch.clamp(x, min=1e-10))\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, z_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        #Encoder\n",
        "        self.ln_en1 = nn.Linear(28*28+class_size,1000)\n",
        "        #self.ln_en2 = nn.Linear(1000, 200)\n",
        "        self.ln_en_mean = nn.Linear(1000,z_dim)\n",
        "        self.ln_en_std = nn.Linear(1000,z_dim)\n",
        "\n",
        "        #Decoder\n",
        "        self.ln_de1 = nn.Linear(z_dim+class_size,1000)\n",
        "        #self.ln_de2 = nn.Linear(200, 1000)\n",
        "        self.ln_de3 = nn.Linear(1000, 28*28)\n",
        "\n",
        "    def encoder(self, x):\n",
        "        x = F.relu(self.ln_en1(x))\n",
        "        #x = F.relu(self.ln_en2(x))\n",
        "        mean = self.ln_en_mean(x)\n",
        "        std = F.softplus(self.ln_en_std(x))\n",
        "        return mean, std\n",
        "\n",
        "    def re_trick(self, mean, std):\n",
        "        if self.training:\n",
        "            epsilon = torch.randn(mean.shape).to(device)\n",
        "            return mean + std * epsilon\n",
        "        else:\n",
        "            return mean\n",
        "\n",
        "    def decoder(self, z):\n",
        "        x = F.relu(self.ln_de1(z))\n",
        "        #x = F.relu(self.ln_de2(x))\n",
        "        x = torch.sigmoid(self.ln_de3(x))\n",
        "        return x\n",
        "\n",
        "    def forward(self, x, label):\n",
        "        one_hot_label = F.one_hot(label, num_classes=class_size).to(torch.float32)\n",
        "        x_label = torch.cat((x, one_hot_label), dim = 1)\n",
        "        mean, std = self.encoder(x_label)\n",
        "        z = self.re_trick(mean, std)\n",
        "        z_label = torch.cat((z,one_hot_label), dim=1)\n",
        "        x = self.decoder(z_label)\n",
        "        return x, z\n",
        "\n",
        "    def loss(self, x, label):\n",
        "        one_hot_label = F.one_hot(label, num_classes=class_size).to(torch.float32)\n",
        "        x_label = torch.cat((x, one_hot_label), dim = 1)\n",
        "\n",
        "        mean, std = self.encoder(x_label)\n",
        "        KL = -0.5 * torch.mean(torch.sum(1+torch_log(std**2) - mean**2 - std**2, dim = 1))\n",
        "\n",
        "        z = self.re_trick(mean, std)\n",
        "\n",
        "        z_label = torch.cat((z,one_hot_label), dim=1)\n",
        "        y = self.decoder(z_label)\n",
        "\n",
        "        recon = torch.mean(torch.sum((y-x)**2, dim=1))\n",
        "        #recon = -torch.mean(torch.sum(x*torch_log(y)+(1-x)*torch_log(1-y), dim=1))\n",
        "        return KL, recon"
      ],
      "metadata": {
        "id": "s5F2AunNR3qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#学習\n",
        "model  = VAE(z_dim).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "epoch_train_losses = []\n",
        "epoch_val_losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    batch_train_loss = []\n",
        "    batch_val_loss = []\n",
        "\n",
        "    model.train()\n",
        "    for x, label in train_loader: #train_loader\n",
        "        x = x.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "        KL, recon = model.loss(x, label)\n",
        "        loss = beta * KL + recon\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        batch_train_loss.append(loss.cpu().detach().numpy())\n",
        "    epoch_train_losses.append(np.average(batch_train_loss))\n",
        "\n",
        "    model.eval()\n",
        "    for x, label in val_loader: #val_loader\n",
        "        x = x.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        KL, recon = model.loss(x, label)\n",
        "        loss = beta * KL + recon\n",
        "        batch_val_loss.append(loss.cpu().detach().numpy())\n",
        "    epoch_val_losses.append(np.average(batch_val_loss))\n",
        "\n",
        "    print(\"{} EPOCH: Train_Loss -> {}, Val_Loss -> {}\".format(epoch, np.average(batch_train_loss), np.average(batch_val_loss)))\n",
        "\n",
        "plt.plot(range(len(epoch_train_losses)), epoch_train_losses, label=\"Train_Loss\")\n",
        "plt.plot(range(len(epoch_val_losses)), epoch_val_losses, label=\"Val_Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "q83f1jZDR4hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#画像確認\n",
        "\n",
        "#元画像\n",
        "fig = plt.figure(figsize=(3,3))\n",
        "for i in range(9):\n",
        "    x, _ = val_data[i] #val_data\n",
        "    im = x.view(-1,28, 28).permute(1,2,0).squeeze().numpy()\n",
        "\n",
        "    ax = fig.add_subplot(3,3,i+1)\n",
        "    ax.imshow(im)\n",
        "\n",
        "#再構成画像\n",
        "model.eval()\n",
        "\n",
        "fig = plt.figure(figsize=(3,3))\n",
        "for i in range(9):\n",
        "    x, label = val_data[i] #val_data\n",
        "    label = torch.tensor([label]).to(device)\n",
        "    x = x.unsqueeze(0).to(device)\n",
        "    y, z = model(x, label)\n",
        "    im = y.view(-1, 28, 28).permute(1,2,0).detach().cpu().squeeze().numpy()\n",
        "\n",
        "    ax = fig.add_subplot(3,3,i+1)\n",
        "    ax.imshow(im)\n",
        "\n",
        "label = torch.tensor([5])\n",
        "one_hot_label = F.one_hot(label, num_classes=class_size).to(torch.float32)\n",
        "\n",
        "#ラベル指定画像生成\n",
        "model.eval()\n",
        "\n",
        "fig = plt.figure(figsize=(3,3))\n",
        "for i in range(9):\n",
        "    z = torch.randn((z_dim), device = device)\n",
        "    z = z.unsqueeze(0).to(device)\n",
        "    one_hot_label = one_hot_label.to(device)\n",
        "    z_label = torch.cat((z,one_hot_label), dim=1)\n",
        "    y = model.decoder(z_label)\n",
        "    im = y.view(-1, 28, 28).permute(1,2,0).detach().cpu().squeeze().numpy()\n",
        "\n",
        "    ax = fig.add_subplot(3,3,i+1)\n",
        "    ax.imshow(im)"
      ],
      "metadata": {
        "id": "YaLMcRx9R8Oe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}